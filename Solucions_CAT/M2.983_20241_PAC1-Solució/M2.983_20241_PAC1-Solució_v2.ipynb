{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkkr1HUBPOcL"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.983 · Aprenentage per reforç</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2024-1 · Màster universitari en Ciència de dades (<i>Data science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEcTs47Ao6C9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Nombre y apellidos:</strong> Indicar aquí el nombre y apellidos\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFR_J-YYXLx-",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# PAC 1 - Solucions tabulars\n",
    "\n",
    "En aquesta pràctica implementarem els diferents mètodes d'aprenentatge per reforç estudiats als Blocs I i II del curs. En concret, ens centrarem en la definició d'un entorn i implementarem els diferents mètodes per buscar una solució òptima del problema.\n",
    "\n",
    "**<u>Important</u>: El lliurament s'ha de fer en format notebook i en format html on es vegi el codi, els resultats i comentaris de cada exercici. És a dir, s'han de lliurar dos fitxers: un amb extensió .ipynb i un altre .html. Per exportar el notebook a html pot fer-se des del menú File $\\to$ Download as $\\to$ HTML. A més s'han de lliurar els 2 arxius que es modificaran dins de la carpeta <code>\\gym_gridworlds</code>, els arxius <code>gridworld.py</code> i <code>\\_\\_init\\_\\_.py</code>.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyFUy1qlDGku"
   },
   "source": [
    "## 1. L'entorn __Gym-Gridworlds__ (1 punt)\n",
    "\n",
    "L'entorn __Gym-Gridworlds__ és un entorn de tercers que es troba referenciat a la web de Gymnasium, concretament a l'apartat 'ENVIRONMENTS/External Environments'.\n",
    "\n",
    "L'entorn consisteix en un agent que es mou en una quadrícula de dimensions configurables. La classe per defecte `Gridworld` implementa una tasca \"anar a l'objectiu\" on l'agent té cinc accions (esquerra, dreta, amunt, avall, romandre al lloc) i una funció de transició predeterminada (seleccionar l'acció \"romandre al lloc\" als estats objectiu acaba l'episodi).\n",
    "\n",
    "El codi i la documentació es troba a https://github.com/sparisi/gym_gridworlds\n",
    "\n",
    "Es recomana llegir atentament la pàgina per familiaritzar-se amb l'entorn.\n",
    "\n",
    "**<u>Nota</u>: L'entorn utilitzat té un mode de renderitzat <code>render\\_mode = \"human\"</code> que permet observar la quadrícula i el moviment de l'agent en una pantalla adicional utiltzant el paquet <code>pygame</code> de python. Aquest mode de renderitzat només funciona en local. Per a poder executar el codi sense problemes es proporciona un arxiu <code>environment.yml</code> perquè pugueu crear un entorn virtual amb els paquets necessaris.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBkO2FuFJdH-"
   },
   "source": [
    "Començarem carregant un dels múltiples entorns pre-dissenyats i veurem les seves principals característiques, executant un episodi de prova."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBrIWvZmDB6H"
   },
   "source": [
    "### 1.1. Càrrega de dades (0.5 punts)\n",
    "\n",
    "El següent codi carrega els paquets necessaris per a l'exemple.\n",
    "\n",
    "Comencem instal·lant Gymnasium (això només s'ha de fer una vegada si no ho teniu instal·lat ja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7035,
     "status": "ok",
     "timestamp": 1729206552620,
     "user": {
      "displayName": "Luis Esteve Elfau",
      "userId": "04659768458370690763"
     },
     "user_tz": -120
    },
    "id": "qMuA4JjZXLx_",
    "outputId": "99100ad3-caf9-4cfe-9636-d02536659505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium==1.0.0 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from gymnasium==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from gymnasium==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from gymnasium==1.0.0) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from gymnasium==1.0.0) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from gymnasium==1.0.0) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\birth\\anaconda3\\envs\\rl_2024_pac1\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium==1.0.0) (3.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qNO2StvHo6DD",
    "outputId": "467036e4-1515-42b8-91f4-b685bf78f461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La versió de Gymnasium utilitzada en aquesta PAC s la 1.0.0, comprova-ho a continuació\n",
      "Gymnasium Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "print(\"La versió de Gymnasium utilitzada en aquesta PAC s la 1.0.0, comprova-ho a continuació\")\n",
    "print(\"Gymnasium Version:\", gym.__version__) # 0.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j27liozvo6DE"
   },
   "source": [
    "A continuació clonem el repositori de l'entorn (això només s'ha de fer una vegada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81RCuLEwej1O"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/sparisi/gym_gridworlds.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hC5cWEHo6DG"
   },
   "source": [
    "Entrem dins del directori `gym_gridworlds` i l'instal·lem en mode editable (això només s'ha de fer una vegada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ne58OSTe2Sa"
   },
   "outputs": [],
   "source": [
    "!cd gym_gridworlds\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 7016,
     "status": "ok",
     "timestamp": 1729206587859,
     "user": {
      "displayName": "Luis Esteve Elfau",
      "userId": "04659768458370690763"
     },
     "user_tz": -120
    },
    "id": "R3t9AqNLZ549",
    "outputId": "d3c79fd1-df15-46fc-8ad3-843090119b33"
   },
   "source": [
    "Importem els paquets necessaris per la resta de la PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h5y5sIqBPPxr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import time\n",
    "import gym_gridworlds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TOZsvbEo6DI"
   },
   "source": [
    "Creem l'entorn mitjançant la instanciació d'un objecte de classe `Gridworld` (en executar la instrucció `env = gym.make(\"Gym-Gridworlds/Full-4x5-v0\", render_mode=\"human\")`) i imprimim per pantalla el tipus de l'espai d'accions i de l'espai d'observacions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1914,
     "status": "ok",
     "timestamp": 1729206611289,
     "user": {
      "displayName": "Luis Esteve Elfau",
      "userId": "04659768458370690763"
     },
     "user_tz": -120
    },
    "id": "ej5qlR-OaTLi",
    "outputId": "e7c8876c-b829-4dc3-dc91-8ca0fdcb8314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(20) \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Full-4x5-v0\", render_mode=\"human\")\n",
    "env.reset()\n",
    "env.render()\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx8Y14xUo6DJ"
   },
   "source": [
    "L'entorn generat té el següent aspecte (comprovar-ho a la finestra emergent de <code>pygame</code> que es genera a l'executar <code>env.render()</code>):\n",
    "<br><br>\n",
    "<img src=\"images/Gym-Gridworld_4x5.png\" alt=\"Mi imagen\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "En aquest entorn podem veure una sèrie de caselles i figures que es descriuen a continuació:\n",
    "\n",
    "<ul>\n",
    "  <li>Les caselles negres són buides.</li>\n",
    "  <li>Les caselles negres amb fletxes grises són caselles on l'agent només es pot moure en una direcció (les altres accions fallaran).</li>\n",
    "  <li>Les caselles vermelles donen recompenses negatives (com més brillants, més negatives).</li>\n",
    "  <li>Les caselles verdes donen recompenses positives (com més brillants, més altes).</li>\n",
    "  <li>Les caselles grogues són arenes movedisses, on totes les accions fallaran amb un 90% de probabilitat.</li>\n",
    "  <li>L'agent és el cercle blau.</li>\n",
    "</ul>\n",
    "\n",
    "A més, hi ha altres tipus de caselles:\n",
    "\n",
    "<ul>\n",
    "  <li>Les caselles blanques són pous (caminar-hi comporta una gran recompensa negativa i l'episodi acaba).</li>\n",
    "  <li>Les caselles porpres són parets (l'agent no hi pot passar).</li>\n",
    "  <li>Una fletxa taronja indica l'última acció de l'agent.</li>\n",
    "  <li>Un punt taronja indica que l'agent no va intentar moure's amb la seva última acció.</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P0mtfJco6DJ"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 1.1</strong> (0.5 pts)\n",
    "\n",
    "Analitzar la [documentació](https://github.com/sparisi/gym_gridworlds) i el codi de l'entorn que es troba a <code>\\gym_gridworlds\\gridworld.py</code> per respondre a les següents preguntes:\n",
    "<ul>    \n",
    "    <li>Descriure l'espai d'accions de l'entorn: quantes accions hi ha? a què correspòn cadascuna d'elles?</li>\n",
    "    <li>Quina és la casella inicial? Es pot canviar?</li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHFTLUP5o6DJ"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Hi ha 5 accions diferents.</li>\n",
    "    <ul>\n",
    "        <li>0: \"Move Left\"</li>\n",
    "        <li>1: \"Move Down\"</li>\n",
    "        <li>2: \"Move Right\"</li>\n",
    "        <li>3: \"Move Up\"</li>\n",
    "        <li>4: \"Stay\"</li>\n",
    "    </ul>\n",
    "<li>En quant a la casella inicial:</li>\n",
    "    <ul>\n",
    "        <li>Per defecte es troba a dalt a l'esquerra.</li>\n",
    "        <li>Es pot canviar fent una sub-classe de la classe <code>Gridworld</code> i re-escribint el mètode <code>_reset()</code></li>\n",
    "    </ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXpl0ErhE_I1"
   },
   "source": [
    "### 1.2. Execució d'un episodi (0.5 punts)\n",
    "\n",
    "A continuació, realitzarem l'execució d'un episodi de l'entorn *Gym-Gridworlds/Full-4x5-v0* utilitzant un agent que selecciona les accions de forma aleatòria.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "84mPbgBGE1zz",
    "outputId": "4e419353-a572-44de-d917-1cc16bc3dfa0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n",
      "Step 1. Action: Stay -> Obs: 0 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 2. Action: Stay -> Obs: 0 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 3. Action: Left -> Obs: 0 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 4. Action: Stay -> Obs: 0 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 5. Action: Down -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 6. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 7. Action: Stay -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 8. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 9. Action: Right -> Obs: 11 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 10. Action: Up -> Obs: 6 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 11. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 12. Action: Right -> Obs: 6 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 13. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 14. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 15. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 16. Action: Up -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 17. Action: Left -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 18. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 19. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 20. Action: Right -> Obs: 11 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 21. Action: Down -> Obs: 16 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 22. Action: Left -> Obs: 15 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 23. Action: Up -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 24. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 25. Action: Stay -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 26. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 27. Action: Stay -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 28. Action: Right -> Obs: 11 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 29. Action: Left -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 30. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 31. Action: Up -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 32. Action: Stay -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 33. Action: Down -> Obs: 10 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 34. Action: Right -> Obs: 11 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 35. Action: Stay -> Obs: 11 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 36. Action: Right -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 37. Action: Left -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 38. Action: Stay -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 39. Action: Left -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 40. Action: Right -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 41. Action: Up -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 42. Action: Up -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 43. Action: Down -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 44. Action: Right -> Obs: 12 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 45. Action: Up -> Obs: 7 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 46. Action: Left -> Obs: 6 and reward: -10.0. Terminated False. Truncated False.\n",
      "Step 47. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 48. Action: Left -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 49. Action: Stay -> Obs: 5 and reward: 0.0. Terminated False. Truncated False.\n",
      "Step 50. Action: Up -> Obs: 0 and reward: 0.0. Terminated False. Truncated True.\n",
      "Episode finished after 50 timesteps and reward was -10.0 \n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem l'entorn\n",
    "obs, info = env.reset()\n",
    "t, total_reward, terminated, truncated = 0, 0, False, False\n",
    "\n",
    "print(\"Obs inicial: {} \".format(obs))\n",
    "\n",
    "switch_action = {\n",
    "        0: \"Left\",\n",
    "        1: \"Down\",\n",
    "        2: \"Right\",\n",
    "        3: \"Up\",\n",
    "        4: \"Stay\",\n",
    "    }\n",
    "done = False\n",
    "while not done:\n",
    "\n",
    "    # Triar una acció aleatòria (aquesta és la implementació de l'agent)\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Executar l'acció i esperar la resposta de l'entorn\n",
    "    new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    # Imprimir time-step\n",
    "    print(\"Step {}. Action: {} -> Obs: {} and reward: {}. Terminated {}. Truncated {}.\".format(t+1, switch_action[action], new_obs, reward, terminated, truncated))\n",
    "\n",
    "    # Actualitzar variables\n",
    "    obs = new_obs\n",
    "    total_reward += reward\n",
    "    t += 1\n",
    "    time.sleep(0.5) #S'afegeix per alentir el renderitzat i poder apreciar els moviments de l'agent\n",
    "\n",
    "print(\"Episode finished after {} timesteps and reward was {} \".format(t, total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKN4LyXHo6DK"
   },
   "source": [
    "Es recomana analitzar el codi anterior, executar-lo vàries vegades i observar el renderitzat en la finestra emergent externa abans de contestar el següent exercici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raIg3cNao6DL"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 1.2</strong> (0.5 pts)\n",
    "\n",
    "Una vegada executat l'episodi, i en base a l'anàlisi de la documentació i del codi de l'entorn, respondre a les següents preguntes:\n",
    "<ul>\n",
    "    <li>Descriure l'espai d'estats: en què consisteixen els estats? com es codifiquen per defecte?</li>\n",
    "    <li>Descriure el senyal de recompensa: quins valors pot prendre? en quines situacions es rep cada valor?</li>\n",
    "    <li>Quan finalitza un episodi?</li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKFHJQeeo6DL"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>L'espai d'estats consisteix en un conjunt de números enters que identifiquen cada casella:</li>\n",
    "    <ul>\n",
    "        <li>El seu rang és [0,nombre de caselles-1]</li>\n",
    "        <li>La numeració comença amb 0 a la casella de dalt a l'esquerra i es va propagant d'esquerra a dreta i de dalt a baix.</li>\n",
    "    </ul>\n",
    "    <li>El senyal de recompensa és una variable real que pot prendre els següents valors en funció dels estats i les accions seleccionades:</li>\n",
    "    <ul>\n",
    "        <li>Seleccionar l'acció <code>STAY</code> a la casella objectiu (color verd brillant): +1</li>\n",
    "        <li>Seleccionar l'acció <code>STAY</code> a la casella objectiu de distracció (color verd fosc): +0.1</li>\n",
    "        <li>Qualsevol acció en caselles de penalització (vermell brillant): -10</li>\n",
    "        <li>Qualsevol acció en caselles de penalització petita (vermell fosc, granat): -0.1</li>\n",
    "        <li>Caminar sobre una casella de pou (blanx): -100</li>\n",
    "        <li>Altrament: 0</li>\n",
    "    </ul>\n",
    "    <li>De manera predeterminada, un episodi finalitza si passa alguna de les situacions següents:</li>\n",
    "    <ul>\n",
    "        <li>S'obté una recompensa positiva (terminació).</li>\n",
    "        <li>Caminar sobre una casella de pou (terminació).</li>\n",
    "        <li>La longitud de l'episodi arriba a <code>max_episode_steps</code> (truncament).</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6L2Jw66o6DL"
   },
   "source": [
    "Tanquem l'entorn perquè als següents apartats en crearem un de nou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LTMzWO_ko6DL"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc_f31JOkh2d"
   },
   "source": [
    "## 2. Creació d'un entorn propi (1,5 punts)\n",
    "\n",
    "L'entorn *Gym-Gridworld* té diversos arguments que poden ser modificats:\n",
    "\n",
    "* La dimensió de la quadrícula.\n",
    "* El tipus de cada casella.\n",
    "* La posició de les caselles de sortida i d'arribada.\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WniTr5sdXLyC"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 2.1</strong> (0,75 punts)\n",
    "\n",
    "Crear un entorn nou com el que es descriu a continuació:\n",
    "\n",
    "<ul>\n",
    "  <li>Graella 4x4</li>\n",
    "  <li>Les 4 caselles centrals son de tipus paret (color porpra).</li>\n",
    "  <li>Casella d'inici a dalt a l'esquerra (posició per defecte).</li>\n",
    "  <li>Casella final (color verd brillant) a baix a la dreta.</li>\n",
    "  <li>La casella de la dreta del tot de la primera fila que sigui amb penalització gran (color vermell brillant).</li>\n",
    "  <li>La resta de caselles, en comptes de ser normals (color negre) posar-les amb una petita penalització (color vermell fosc).</li>\n",
    "</ul>\n",
    "\n",
    "Per a realitzar l'entorn:\n",
    "<ul>\n",
    "  <li>Heu d'afegir la graella al diccionari <code>GRIDS</code> de l'arxiu <code>\\gym_gridworlds\\gridworld.py</code> (utilitzeu com a clau de l'entrada al diccionari <code>\"4X4_Ex2\"</code>.)</li>\n",
    "  <li>Heu de registrar l'entorn a l'arxiu <code>\\gym_gridworlds\\__init__.py</code> amb les següents dades:</li>\n",
    "      <ul>\n",
    "          <li><code>id=\"Gym-Gridworlds/Ex2-4x4-v0\"</code></li>\n",
    "          <li><code>entry_point=\"gym_gridworlds.gridworld:Gridworld\"</code></li>\n",
    "          <li><code>max_episode_steps=100</code></li>\n",
    "          <li><code>kwargs={\"grid\": \"4X4_Ex2\",}</code></li>\n",
    "       </ul>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d0qpzwLo6DM"
   },
   "source": [
    "Una vegada afegit i registrat el nou entorn re-inicieu el kernel del Notebook per a que es pugui carregar i executar.\n",
    "\n",
    "Si tot ha anat bé, després d'executar el següent codi, hauríeu d'obtenir un entorn amb el següent aspecte:\n",
    "<br><br>\n",
    "<img src=\"images/Gym-Gridworld_Ex2_4x4.png\" alt=\"Mi imagen\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZIKcFYi-IX-C",
    "outputId": "64eabc36-374f-42f0-cb58-833a5c224baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(16) \n"
     ]
    }
   ],
   "source": [
    "import gym_gridworlds\n",
    "env = gym.make(\"Gym-Gridworlds/Ex2-4x4-v0\", render_mode=\"human\")\n",
    "env.reset()\n",
    "env.render()\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AVvZVSqIggI"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 2.2</strong> (0,25 punts)\n",
    "\n",
    "A continuació, implementar un agent que dugui a terme una política aleatòria. Comprovar que les caselles visitades i les recompenses rebudes es corresponen amb les accions i l'entorn programat.\n",
    "\n",
    "Mostrar la trajectòria seguida per l'agent. No cal graficar-la , tan sols mostrar les accions i les caselles visitades en ordre i les recompenses rebudes.\n",
    "\n",
    "Mostrar també el nombre de *steps* i la recompensa total acumulada.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ksk8N63OHpEO",
    "outputId": "4f0a4985-ff4f-416e-80e3-e5196790cdfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem l'entorn\n",
    "obs, info = env.reset()\n",
    "t, total_reward, terminated, truncated = 0, 0, False, False\n",
    "\n",
    "print(\"Obs inicial: {} \".format(obs))\n",
    "\n",
    "switch_action = {\n",
    "        0: \"Left\",\n",
    "        1: \"Down\",\n",
    "        2: \"Right\",\n",
    "        3: \"Up\",\n",
    "        4: \"Stay\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q1B0qogIJB2z",
    "outputId": "c4da12c1-0359-4ebe-d436-161b2c97c0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. Action: Stay -> Obs: 0 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 2. Action: Left -> Obs: 0 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 3. Action: Up -> Obs: 0 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 4. Action: Down -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 5. Action: Stay -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 6. Action: Left -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 7. Action: Stay -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 8. Action: Stay -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 9. Action: Left -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 10. Action: Stay -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 11. Action: Left -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 12. Action: Left -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 13. Action: Up -> Obs: 0 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 14. Action: Down -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 15. Action: Right -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 16. Action: Right -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 17. Action: Down -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 18. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 19. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 20. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 21. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 22. Action: Right -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 23. Action: Left -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 24. Action: Stay -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 25. Action: Up -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 26. Action: Stay -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 27. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 28. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 29. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 30. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 31. Action: Right -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 32. Action: Up -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 33. Action: Down -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 34. Action: Stay -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 35. Action: Left -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 36. Action: Stay -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 37. Action: Left -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 38. Action: Up -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 39. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 40. Action: Up -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 41. Action: Down -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 42. Action: Stay -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 43. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 44. Action: Up -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 45. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 46. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 47. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 48. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 49. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 50. Action: Left -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 51. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 52. Action: Stay -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 53. Action: Up -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 54. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 55. Action: Stay -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 56. Action: Stay -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 57. Action: Up -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 58. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 59. Action: Right -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 60. Action: Left -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 61. Action: Stay -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 62. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 63. Action: Right -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 64. Action: Right -> Obs: 14 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 65. Action: Right -> Obs: 15 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 66. Action: Stay -> Obs: 15 and reward: 1.0. Terminated True. Truncated False.\n",
      "Episode finished after 66 timesteps and total reward was -5.499999999999993 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "\n",
    "    # Triar una acció aleatòria (aquesta és la implementació de l'agent)\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # Executar l'acció i esperar la resposta de l'entorn\n",
    "    new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    # Imprimir time-step\n",
    "    print(\"Step {}. Action: {} -> Obs: {} and reward: {}. Terminated {}. Truncated {}.\".format(t+1, switch_action[action], new_obs, reward, terminated, truncated))\n",
    "\n",
    "    # Actualitzar variables\n",
    "    obs = new_obs\n",
    "    total_reward += reward\n",
    "    t += 1\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Episode finished after {} timesteps and total reward was {} \".format(t, total_reward))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVDVy2tIXLyD"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Pregunta</strong>\n",
    "Quin pot ser l'ojectiu d'utilitzar caselles de collor vermell fosc (amb una petita penalització) en comptes de caselles negres (sense penalització) en l'entrenament dels agents?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttFYwsVtXLyE"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "Això es fa per a condicionar a l'agent a que intenti trobar el camí més ràpid cap a l'objectiu.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQhaSJuIo6DP"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 2.3</strong> (0,5 punts)\n",
    "\n",
    "A continuació, implementar un agent que dugui a terme la política òptima determinista, és a dir, que partint de la casella inicial [0,0] arribi a la casella final (de color verd brillant) amb la màxima recompensa acumulada. Quin és el valor del nombre de passos mínims? Quin és el retorn obtingut?\n",
    "\n",
    "Mostra la trajectòria seguida per l'agent i el retorn obtingut. No cal graficar-la, tan sols mostrar les accions i les caselles visitades en ordre i el retorn (recompensa total acumulada).\n",
    "\n",
    "Comenta els resultats.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "07kPrBwtXLyD",
    "outputId": "39e29cbd-27ca-4b03-d747-27cc55aee541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem l'entorn\n",
    "obs, info = env.reset()\n",
    "t, total_reward, terminated, truncated = 0, 0, False, False\n",
    "\n",
    "print(\"Obs inicial: {} \".format(obs))\n",
    "\n",
    "switch_action = {\n",
    "        0: \"Left\",\n",
    "        1: \"Down\",\n",
    "        2: \"Right\",\n",
    "        3: \"Up\",\n",
    "        4: \"Stay\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FkX27sGtXLyD",
    "outputId": "0c1cc219-0956-4059-fe91-8dc52f3b5783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. Action: Down -> Obs: 4 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 2. Action: Down -> Obs: 8 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 3. Action: Down -> Obs: 12 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 4. Action: Right -> Obs: 13 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 5. Action: Right -> Obs: 14 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 6. Action: Right -> Obs: 15 and reward: -0.1. Terminated False. Truncated False.\n",
      "Step 7. Action: Stay -> Obs: 15 and reward: 1.0. Terminated True. Truncated False.\n",
      "Episode finished after 7 timesteps and total reward was 0.4 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "# Definim una llista amb la política òptima\n",
    "optimal_policy = [1, 1, 1, 2, 2, 2, 4]\n",
    "\n",
    "# Li donem la volta a la llista per treure'ls d'un en un en l'ordre correcte\n",
    "\n",
    "optimal_policy.reverse()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "\n",
    "    # Extreure una acció de la llista d'accions òptimes\n",
    "    action = optimal_policy.pop()\n",
    "\n",
    "    new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    # Imprimir time-step\n",
    "    print(\"Step {}. Action: {} -> Obs: {} and reward: {}. Terminated {}. Truncated {}.\".format(t+1, switch_action[action], new_obs, reward, terminated, truncated))\n",
    "\n",
    "\n",
    "    # Actualitzar variables\n",
    "    obs = new_obs\n",
    "    total_reward += reward\n",
    "    t += 1\n",
    "\n",
    "print(\"Episode finished after {} timesteps and total reward was {} \".format(t, total_reward))\n",
    "env.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGZix28qo6DQ"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "La política òptima és aquella que provoca que l'agent arribi a la casella final (de color verd brillant) evitant la casella de màxima penalització (de color vermell brillant).\n",
    "\n",
    "S'aconsegueix en 7 passes i el retorn és de 0.4.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I9svxF9XLyG"
   },
   "source": [
    "## 3. Mètodes de Montecarlo (2 punts)\n",
    "\n",
    "L'objectiu d'aquest apartat és realitzar una estimació de la política òptima mitjançant els mètodes de Montecarlo. En concret estudiarem l'algoritme *On-policy first-visit MC control* (per a polítiques $\\epsilon$-soft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8GHrBhaXLyG"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 3.1</strong> (1 punt)\n",
    "\n",
    "Implementar l'Algorisme 3 explicat en el mòdul \"Mètodes de Montecarlo\": *On-policy first-visit MC control (per a polítiques $\\epsilon$-soft)* utilitzant els següents paràmetres:\n",
    "    \n",
    "<ul>\n",
    "  <li>Nombre d'episodis = 50.000</li>\n",
    "  <li>Epsilon inicial = 0,5</li>\n",
    "  <li>Factor de decaïment d'epsilon (*epsilon decay*) = 0,999</li>\n",
    "  <li>Mínim valor d'epsilon (*epsilon_min*) = 0,05</li>\n",
    "  <li>Actualitzar epsilon segons:  $$\\textrm{max}(\\epsilon · \\epsilon_{\\textrm{decay}}, \\epsilon_{\\textrm{min}})$$</li>\n",
    "  <li>Factor de descompte = 1</li>\n",
    "</ul>\n",
    "<b>Nota: als entrenaments dels agents es recomana utilitzar els entorns amb <code>render_mode = None</code> per a agilitzar l'execució.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PzULGiJpXLyG"
   },
   "outputs": [],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "## Solució adaptada de\n",
    "## https://github.com/dennybritz/reinforcement-learning/tree/master/MC\n",
    "import gym_gridworlds\n",
    "env = gym.make(\"Gym-Gridworlds/Ex2-4x4-v0\", render_mode=None)\n",
    "\n",
    "env.reset()\n",
    "#env.render()\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, num_Actions):\n",
    "    \"\"\"\n",
    "    Crea una política epsilon-greedy basada en una función de valor de acción Q y epsilon\n",
    "\n",
    "    Args:\n",
    "        Q: Un diccionario cuya correspondencia es state -> action-values.\n",
    "           Cada valor es un array de numpy de longitud num_Actions (see below)\n",
    "        epsilon: La probabilidad de seleccionar una acción aleatoria (float entre 0 and 1).\n",
    "        num_Actions: Número de acciones del entorno. (en el caso del WIndyGridWorld es 4)\n",
    "\n",
    "    Returns:\n",
    "        Una función que tome como argumento la observación y devuelva como resultado\n",
    "        las probabilidades de cada acción como un array de numpy de longitud num_Actions.\n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "\n",
    "        A = np.ones(num_Actions, dtype=float) * epsilon / num_Actions\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "\n",
    "        return A\n",
    "\n",
    "    return policy_fn\n",
    "\n",
    "def mc_control_on_policy_epsilon_greedy(env, num_episodes, discount=1.0, epsilon=0.1, epsilon_decay = 0.9, epsilon_min = 0.01):\n",
    "    \"\"\"\n",
    "    Control mediante métodos de Montecarlo usando políticas Epsilon-Greedy\n",
    "    Encuentra una política epsilon-greedy.\n",
    "\n",
    "    Args:\n",
    "        env: entorno OpenAI gym.\n",
    "        num_episodes: Número de episodios de la muestra.\n",
    "        discount: factor de descuento.\n",
    "        epsilon: La probabilidad de seleccionar una acción aleatoria (float entre 0 and 1)\n",
    "\n",
    "    Returns:\n",
    "        Una tupla (Q, policy).\n",
    "        Q: Un diccionario cuya correspondencia es state -> action-values.\n",
    "        policy: Una función que toma como argumento la observación y devuelve como resultado\n",
    "                las probabilidades de cada acción\n",
    "    \"\"\"\n",
    "\n",
    "    # Almacenamos la suma y el número de retornos de cada estado para calcular\n",
    "    # el promedio. Podríamos usar un array para guardar todos los retornos\n",
    "    # (como en el libro) pero es ineficiente en términos de memoria.\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "\n",
    "    # La función de valor de acción Q.\n",
    "    # Un diccionario anidado cuya correspondencia es state -> (action -> action-value).\n",
    "    # Inicialmente la inicializamos a cero\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    # La política que estamos siguiendo\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        # Imprimimos en qué episodio estamos, útil para debugar.\n",
    "        if i_episode % 50 == 0:\n",
    "            print(\"\\rEpisode {}/{}. Epsilon {}\".format(i_episode, num_episodes, epsilon), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Generamos un episodio y lo almacenamos\n",
    "        # Un episodio es un array de las tuplas (state, action, reward)\n",
    "        episode = []\n",
    "        state, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            probs = policy(state)\n",
    "            action = np.random.choice(np.arange(len(probs)), p=probs)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode.append((state, action, reward))\n",
    "            if done:\n",
    "                break\n",
    "            state = next_state\n",
    "\n",
    "        # Encontramos todos los pares (estado, acción) que hemos visitado en este episodio\n",
    "        # Convertimos cada estado en una tupla para poder usarlo como clave del diccionario\n",
    "        sa_in_episode = set([(x[0], x[1]) for x in episode])\n",
    "        for state, action in sa_in_episode:\n",
    "            sa_pair = (state, action)\n",
    "            # Encontramos la primera aparición del par (estado, acción) en el episodio\n",
    "            first_occurence_idx = next(i for i,x in enumerate(episode)\n",
    "                                       if x[0] == state and x[1] == action)\n",
    "            # Sumamos todas las recompensas desde la primera aparición\n",
    "            G = sum([x[2]*(discount**i) for i,x in enumerate(episode[first_occurence_idx:])])\n",
    "            # Calculamos el retorno promedio para este estado en todos los episodios muestreados\n",
    "            returns_sum[sa_pair] += G\n",
    "            returns_count[sa_pair] += 1.0\n",
    "            Q[state][action] = returns_sum[sa_pair] / returns_count[sa_pair]\n",
    "\n",
    "        # Actualitzem epsilon\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        # La política es millora implícitament en canviar els valors de Q\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DvmxkGZ3o6DX",
    "outputId": "ed83848a-bbb2-4d39-e983-f5ef51aa276a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50000/50000. Epsilon 0.05121889634088815CPU times: total: 44 s\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######################## SOLUCIÓ ###########################\n",
    "Q_mc = mc_control_on_policy_epsilon_greedy(env, num_episodes=50000, discount=1, epsilon=0.5, epsilon_decay = 0.999, epsilon_min = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z-VxeHfXLyH"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 3.2</strong> (0.5 punts)\n",
    "Implementar una funció que imprimeixi per pantalla la política trobada per a cada casella a partir de la funció Q (aplicant una política <i>greedy</i>) i executar-la amb la funció Q obtinguda de l'entrenament del mètode de Montecarlo.\n",
    "Es tracta de la política òptima?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rhrFr8xtXLyK"
   },
   "outputs": [],
   "source": [
    "def print_policy(Q, width, height):\n",
    "\n",
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "    switch_action = {\n",
    "        0: \"Left\",\n",
    "        1: \"Down\",\n",
    "        2: \"Right\",\n",
    "        3: \"Up\",\n",
    "        4: \"Stay\",\n",
    "    }\n",
    "    for j in range(height):\n",
    "        print(\"------------------------------------------\")\n",
    "        for i in range(width):\n",
    "            arr = np.array(Q[j*height+i])\n",
    "            act = int(arr.argmax())\n",
    "            a = switch_action[act]\n",
    "            print(\"  %s  |\" % a, end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"----------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "i22S8zaNXLyK",
    "outputId": "8a6752a0-2ae1-49a8-b1ab-c527575ddc26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Stay  |\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "print_policy(Q_mc,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDuoGZgFo6DY"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "La política obtinguda és l'òptima per a totes les caselles la majoria de vegades que s'executa el codi amb els hiperparàmetres obtinguts, però hi ha vegades (no és el cas d'aquesta execució) que a la casella 3 (a dalt a la dreta del tot), l'acció escollida és 'Left' i hauria de ser 'Down'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPvEnKWHXLyL"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 3.3</strong> (0.5 punts)\n",
    "Executar un episodi amb la política trobada i mostrar la trajectòria de l'agent i el retorn obtingut. Comentar els resultats.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yYSTtAGjXLyL"
   },
   "outputs": [],
   "source": [
    "def execute_episode(Q, env):\n",
    "\n",
    "    ######################## SOLUCIÓ ###########################\n",
    "    obs, _ = env.reset()\n",
    "    t, total_reward, done = 0, 0, False\n",
    "    print(\"Obs inicial: {} \".format(obs))\n",
    "\n",
    "    switch_action = {\n",
    "        0: \"Left\",\n",
    "        1: \"Down\",\n",
    "        2: \"Right\",\n",
    "        3: \"Up\",\n",
    "        4: \"Stay\",\n",
    "    }\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        # Triem la política òptima en cada cas (el màxim de la política Epsilon-Greedy)\n",
    "        arr = np.array(Q[obs])\n",
    "        action = arr.argmax()\n",
    "\n",
    "        # Executem l'acció i esperem la resposta de l'entorn\n",
    "        new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        obs = new_obs\n",
    "        print(\"Action: {} -> Obs: {} and reward: {}\".format(switch_action[action], obs, reward))\n",
    "        done = truncated or terminated\n",
    "\n",
    "\n",
    "        total_reward += reward\n",
    "        t += 1\n",
    "        if truncated:\n",
    "            print(\"Number of time-septs exceeds 100. STOP episode.\")\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(\"Episode finished after {} timesteps and reward was {} \".format(t, total_reward))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WM2JvlXCXLyL",
    "outputId": "d1778590-979e-46b3-d5e2-95880fb79b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n",
      "Action: Down -> Obs: 4 and reward: -0.1\n",
      "Action: Down -> Obs: 8 and reward: -0.1\n",
      "Action: Down -> Obs: 12 and reward: -0.1\n",
      "Action: Right -> Obs: 13 and reward: -0.1\n",
      "Action: Right -> Obs: 14 and reward: -0.1\n",
      "Action: Right -> Obs: 15 and reward: -0.1\n",
      "Action: Stay -> Obs: 15 and reward: 1.0\n",
      "Episode finished after 7 timesteps and reward was 0.4 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "execute_episode(Q_mc,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrct3io-o6Da"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "S'aconsegueix arribar a l'objectiu en 7 passes i el retorn és de 0.4.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzg9iWfjXLyL"
   },
   "source": [
    "## 4. Mètodes d'Diferència Temporal (3.5 punts)\n",
    "\n",
    "L'objectiu d'aquest apartat és realitzar una estimació de la política òptima mitjançant els mètodes de Diferència Temporal en l'entorn *Gridworld* creat anteriorment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki2gKTTgo6Da"
   },
   "source": [
    "### 4.1. Mètode SARSA (2 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3xqC9vCXLyL"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio 4.1.1</strong> (1 pt)\n",
    "\n",
    "Implementar l'algoritme *SARSA* explicat al mòdul 6 \"Aprenentatge per Diferència Temporal\" y executar-lo utilizant els següents paràmetres:\n",
    "<ul>    \n",
    "    <li>Número d'episodis = 10.000</li>\n",
    "    <li>learning rate = 0,2</li>\n",
    "    <li>discount factor = 1</li>\n",
    "    <li>epsilon = 0,5</li>\n",
    "    <li>epsilon decay = 0,9</li>\n",
    "    <li>mínim valor d'epsilon = 0,05</li>\n",
    "</ul>\n",
    "Actualitzar el valor d'epsilon segons: $$\\textrm{max}(\\epsilon · \\epsilon_{\\textrm{decay}}, \\epsilon_{\\textrm{min}})$$\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e7kSqiTXo6De",
    "outputId": "5b3f1b1d-b202-40d4-df05-bc4ac20fb2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(16) \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Ex2-4x4-v0\", render_mode=None)\n",
    "\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AVl8eO3no6De"
   },
   "outputs": [],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "def update_Q_sarsa(alpha, gamma, Q, state, action, reward, next_state=None, next_action=None):\n",
    "    \"\"\"Returns updated Q-value for the most recent experience.\"\"\"\n",
    "    current = Q[state][action]  # estimate in Q-table (for current state, action pair)\n",
    "    # get value of state, action pair at next time step\n",
    "    Qsa_next = Q[next_state][next_action] if next_state is not None else 0\n",
    "    target = reward + (gamma * Qsa_next)               # construct TD target\n",
    "    TD_error = target-current\n",
    "    new_value = current + (alpha * TD_error) # get updated value\n",
    "    return new_value, TD_error\n",
    "\n",
    "def epsilon_greedy(Q, state, nA, eps):\n",
    "    \"\"\"Selects epsilon-greedy action for supplied state.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        Q (dictionary): action-value function\n",
    "        state (int): current state\n",
    "        nA (int): number actions in the environment\n",
    "        eps (float): epsilon\n",
    "    \"\"\"\n",
    "    if np.random.random() > eps: # select greedy action with probability epsilon\n",
    "        return np.argmax(Q[state])\n",
    "    else:                     # otherwise, select an action randomly\n",
    "        return np.random.choice(np.arange(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-RmgXQgwo6De"
   },
   "outputs": [],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "def sarsa(env, num_episodes, alpha, gamma=1.0, epsilon=1, epsdecay=0.99, epsmin=0.01):\n",
    "    nA = env.action_space.n                # number of actions\n",
    "    Q = defaultdict(lambda: np.zeros(nA))  # initialize empty dictionary of arrays\n",
    "    deltas = []\n",
    "    eps =epsilon\n",
    "\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        # monitor progress\n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        score = 0                                             # initialize score\n",
    "        state, info = env.reset()                                   # start episode\n",
    "        action = epsilon_greedy(Q, state, nA, eps)            # epsilon-greedy action selection\n",
    "        biggest_change = 0\n",
    "\n",
    "        while True:\n",
    "            next_state, reward, terminated, truncated, info = env.step(action) # take action A, observe R, S'\n",
    "            done = terminated or truncated\n",
    "            score += reward                                   # add reward to agent's score\n",
    "            if terminated:\n",
    "                Q[state][action], TD_error = update_Q_sarsa(alpha, gamma, Q, \\\n",
    "                                                  state, action, reward)\n",
    "            else:\n",
    "                next_action = epsilon_greedy(Q, next_state, nA, eps) # epsilon-greedy action\n",
    "                old_q = Q[state][action]\n",
    "                Q[state][action], TD_error = update_Q_sarsa(alpha, gamma, Q, \\\n",
    "                                                  state, action, reward, next_state, next_action)\n",
    "                state = next_state     # S <- S'\n",
    "                action = next_action   # A <- A'\n",
    "                \n",
    "            if done:\n",
    "                eps = max(epsilon*epsdecay, epsmin)           # actualize value of epsilon\n",
    "                break\n",
    "            biggest_change = max(biggest_change, np.abs(TD_error))\n",
    "        deltas.append(biggest_change)\n",
    "    print(\"\")\n",
    "    return Q, deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "28VcP2XSo6Df",
    "outputId": "863a07f5-07bb-40d2-e094-17d04d97ef13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000\n",
      "CPU times: total: 4.34 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######################## SOLUCIÓ ###########################\n",
    "# obtain the estimated optimal policy and corresponding action-value function\n",
    "Q_sarsa, deltas = sarsa(env, num_episodes=10000, alpha=0.2, gamma= 1, epsilon=0.5, epsdecay=0.9, epsmin=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DiHyZrPo6Df"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 4.1.2</strong> (0.5 pts)\n",
    "Imprimir una gràfica amb l'evolució del més gran error TD de cada episodi. Atès que l'error té molta variància, imprimiu també la mitjana mòbil amb una finestra temporal de 100 episodis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dkwCZWFyo6Dg",
    "outputId": "87352783-d3cc-49d9-c4ca-b326ef15e15f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "window = 100\n",
    "average_deltas = []\n",
    "for idx in range(len(deltas) - window + 1):\n",
    "    average_deltas.append(np.mean(deltas[idx:idx+window]))\n",
    "\n",
    "plt.subplot()\n",
    "plt.title('TD error per episode (moving average)')\n",
    "\n",
    "plt.plot(range(1,len(deltas)+1), deltas,  alpha=0.5, color='blue')\n",
    "plt.plot(range(1,len(average_deltas)+1), average_deltas,  linewidth=1, alpha=1, color='blue')\n",
    "\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Max TD error/episode')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyeJ3h_Zo6Dg"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio 4.1.3</strong> (0.25 pts)\n",
    "Imprimir la política trobada amb el mètode SARSA per a cada estat (podeu re-utilitzar la funció creada a l'apartat anterior dels mètodes MC). Es tracta d'una política òptima?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4VdTWVywo6Dg",
    "outputId": "b638a953-4375-4418-db74-58cef7953957",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Stay  |\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "print_policy(Q_sarsa,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjOv-qalo6Dg"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "La política obtinguda és l'òptima per a totes les caselles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrZzCKuco6Dh"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 4.1.4</strong> (0.25 punts)\n",
    "Executar un episodi amb la política trobada i mostrar la trajectòria de l'agent i el retorn obtingut. Comentar els resultats.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WuqVD8Rho6Dh",
    "outputId": "7872cb7e-ef04-4520-8593-ac21d7559d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n",
      "Action: Down -> Obs: 4 and reward: -0.1\n",
      "Action: Down -> Obs: 8 and reward: -0.1\n",
      "Action: Down -> Obs: 12 and reward: -0.1\n",
      "Action: Right -> Obs: 13 and reward: -0.1\n",
      "Action: Right -> Obs: 14 and reward: -0.1\n",
      "Action: Right -> Obs: 15 and reward: -0.1\n",
      "Action: Stay -> Obs: 15 and reward: 1.0\n",
      "Episode finished after 7 timesteps and reward was 0.4 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "execute_episode(Q_sarsa,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHuQ8h2-o6Dh"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "S'aconsegueix arribar a l'objectiu en 7 passes i el retorn és de 0.4.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crf25Isxo6Dh"
   },
   "source": [
    "### 4.2. Mètode Q-Learning (1.5 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhRFZIyLo6Di"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio 4.2.1</strong> (0.75 pts)\n",
    "\n",
    "Implementar l'algoritme *Q-learning* explicat al mòdul 6 \"Aprenentatge per Diferència Temporal\" y executar-lo utilizant els següents paràmetres:\n",
    "<ul>    \n",
    "    <li>Número de episodios = 5.000</li>\n",
    "    <li>learning rate = 0,4</li>\n",
    "    <li>discount factor = 1</li>\n",
    "    <li>epsilon = 0,5</li>\n",
    "    <li>epsilon decay = 0,9</li>\n",
    "    <li>mínim valor d'epsilon = 0,05</li>\n",
    "</ul>\n",
    "Actualitzar el valor d'epsilon segons: $$\\textrm{max}(\\epsilon · \\epsilon_{\\textrm{decay}}, \\epsilon_{\\textrm{min}})$$\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SuY9efT4XLyL",
    "outputId": "ba9b0251-c273-40cf-fc97-2c9d5cdff681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(16) \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Ex2-4x4-v0\", render_mode=None)\n",
    "\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Dke4cxRZo6Di"
   },
   "outputs": [],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "\n",
    "def update_Q_qlearning(alpha, gamma, Q, state, action, reward, next_state=None):\n",
    "    \"\"\"Returns updated Q-value for the most recent experience.\"\"\"\n",
    "    current = Q[state][action]  # estimate in Q-table (for current state, action pair)\n",
    "    # get value of state, action pair at next time step\n",
    "    Qsa_next = np.max(Q[next_state]) if next_state is not None else 0  # Cambia esta línea\n",
    "    target = reward + (gamma * Qsa_next)      # construct TD target\n",
    "    TD_error = target - current\n",
    "    new_value = current + (alpha * TD_error)  # get updated value\n",
    "    return new_value, TD_error\n",
    "\n",
    "def epsilon_greedy(Q, state, nA, eps):\n",
    "    \"\"\"Selects epsilon-greedy action for supplied state.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        Q (dictionary): action-value function\n",
    "        state (int): current state\n",
    "        nA (int): number actions in the environment\n",
    "        eps (float): epsilon\n",
    "    \"\"\"\n",
    "    if np.random.random() > eps: # select greedy action with probability epsilon\n",
    "        return np.argmax(Q[state])\n",
    "    else:                     # otherwise, select an action randomly\n",
    "        return np.random.choice(np.arange(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7kNXgJ0do6Dj"
   },
   "outputs": [],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "def qlearning(env, num_episodes, alpha, gamma=1.0, epsilon=1, epsdecay=0.99, epsmin=0.01):\n",
    "    nA = env.action_space.n                # number of actions\n",
    "    Q = defaultdict(lambda: np.zeros(nA))  # initialize empty dictionary of arrays\n",
    "    deltas = []\n",
    "    eps = epsilon\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        # monitor progress\n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        score = 0                          # initialize score\n",
    "        state, info = env.reset()          # start episode\n",
    "        biggest_change = 0\n",
    "\n",
    "        while True:\n",
    "            action = epsilon_greedy(Q, state, nA, eps)  # epsilon-greedy action selection\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)  # take action A, observe R, S'\n",
    "            done = terminated or truncated\n",
    "            score += reward                  # add reward to agent's score\n",
    "\n",
    "            old_q = Q[state][action]\n",
    "\n",
    "            if not terminated:\n",
    "                Q[state][action], TD_error = update_Q_qlearning(alpha, gamma, Q, \\\n",
    "                                                                state, action, reward, next_state)\n",
    "            else:\n",
    "                Q[state][action], TD_error = update_Q_qlearning(alpha, gamma, Q, \\\n",
    "                                                                state, action, reward, None)\n",
    "\n",
    "            state = next_state         # S <- S'\n",
    "            if done:\n",
    "                eps = max(epsilon*epsdecay, epsmin)  # set value of epsilon\n",
    "                break\n",
    "            biggest_change = max(biggest_change, np.abs(TD_error))\n",
    "        deltas.append(biggest_change)\n",
    "    print(\"\")\n",
    "    return Q, deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tdTGX9leo6Dj",
    "outputId": "aafcd43b-2226-4b9c-9cec-de74827940f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5000/5000\n",
      "CPU times: total: 2.31 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######################## SOLUCIÓ ###########################\n",
    "# obtain the estimated optimal policy and corresponding action-value function\n",
    "Q_qlearning, deltas = qlearning(env, num_episodes=5000, alpha=0.4, gamma= 1, epsilon=0.5, epsdecay=0.9, epsmin=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8-7XCn3o6Dj"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 4.2.2</strong> (0.25 pts)\n",
    "Imprimir una gràfica amb l'evolució del més gran error TD de cada episodi. Atès que l'error té molta variància, imprimiu també la mitjana mòbil amb una finestra temporal de 100 episodis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0T8mjY69o6Dj",
    "outputId": "355b2f1b-7125-4f02-91c3-43dcc07ecbdf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "window = 100\n",
    "average_deltas = []\n",
    "for idx in range(len(deltas) - window + 1):\n",
    "    average_deltas.append(np.mean(deltas[idx:idx+window]))\n",
    "\n",
    "plt.subplot()\n",
    "plt.title('TD error per episode (moving average)')\n",
    "\n",
    "plt.plot(range(1,len(deltas)+1), deltas,  alpha=0.5, color='blue')\n",
    "plt.plot(range(1,len(average_deltas)+1), average_deltas,  linewidth=1, alpha=1, color='blue')\n",
    "\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Max TD error/episode')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShreNOxio6Dk"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio 4.2.3</strong> (0.25 pts)\n",
    "Imprimir la política trobada amb el mètode Q-learning per a cada estat (podeu re-utilitzar la funció creada a l'apartat anterior). Es tracta d'una política òptima?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tmv7fTIho6Dl",
    "outputId": "cdeecda0-e719-4397-c67b-9fb9552c4a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Stay  |\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "print_policy(Q_qlearning,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__ZLbRN1o6Dl"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "La política obtinguda és l'òptima per a totes les caselles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpxKsr_Fo6Dm"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 4.2.4</strong> (0.25 punts)\n",
    "Executar un episodi amb la política trobada i mostrar la trajectòria de l'agent i el retorn obtingut. Comentar els resultats.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "To0jgR5Ko6Dm",
    "outputId": "0eaf0091-3e13-4ffd-f9f5-74c85ee0985a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 0 \n",
      "Action: Down -> Obs: 4 and reward: -0.1\n",
      "Action: Down -> Obs: 8 and reward: -0.1\n",
      "Action: Down -> Obs: 12 and reward: -0.1\n",
      "Action: Right -> Obs: 13 and reward: -0.1\n",
      "Action: Right -> Obs: 14 and reward: -0.1\n",
      "Action: Right -> Obs: 15 and reward: -0.1\n",
      "Action: Stay -> Obs: 15 and reward: 1.0\n",
      "Episode finished after 7 timesteps and reward was 0.4 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "execute_episode(Q_qlearning,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZrh-N5mo6Dn"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>Comentaris:</strong>\n",
    "<br><br>\n",
    "S'aconsegueix arribar a l'objectiu en 7 passes i el retorn és de 0.4.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjWsuHJEXLyN"
   },
   "source": [
    "## 5. Comparativa dels algoritmes (0.5 punts)\n",
    "\n",
    "En aquest apartat farem una petita comparativa dels mètodes programats en els apartats anteriors.\n",
    "\n",
    "Compararem el comportament dels algoritmes en termens de la política assolida, la duració de l'entrenament i el factor de descompte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9sS5ijiXLyO"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 5.1 - Anàlisi de les polítiques obtingudes i del temps de convergència</strong> (0,25 punts)\n",
    "\n",
    "Realitzar un estudi de les polítiques obtingudes responent a les següents preguntes:\n",
    "<ul>\n",
    "  <li>Tots els algoritmes aconsegueixen arribar a la política òptima?</li>\n",
    "  <li>Triguen el mateix temps en convergir?</li>\n",
    "  <li>A què poden ser degudes les diferències?</li>\n",
    "</ul>\n",
    "<b>Nota: Es recomana excutar cada algoritme diverses vegades per extreure unes conclusions més consistents.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBncS-4SXLyO"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>CONCLUSIONS:</strong>\n",
    "<br>\n",
    "    Tots tres mètodes, amb els hiperparàmetres proporcionats, assoleixen la convergència a la política òptima però els mètodes TD (SARSA i Q-learning) ho fan en molts menys episodis que el mètode de Montecarlo, cosa que fa que el temps d'entrenament dels mètodes TD sigui molt inferior a MC. Això és degut a que els mètodes TD es van actualitzant a cada pas i no han d'esperar fins al final de l'episodi per fer l'actualització de l'algoritme com li passa al mètode de Montecarlo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMobYk_5XLyO"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 5.2 - Influència del factor de descompte (discount factor)</strong> (0,25 punts)\n",
    "\n",
    "Tots els agents s'han entrenat amb recompenses sense descomptar (factor de descompte = 1). A què creus que es deu aquesta elecció? Creus que millorarien els resultats si s'utilitza un factor de descompte diferent? Per què? En cas afirmatiu, selecciona un nou factor de descompte i testeja'l a algun dels algortimes (per exemple a Q-learning).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bS2P1vMYXLyP"
   },
   "outputs": [],
   "source": [
    "#SOLUCIÓ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlNW-nJYXLyP"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>CONCLUSIONS:</strong>\n",
    "<br><br>\n",
    "    \n",
    "Donat que l'única recompensa positiva es troba al final de l'episodi (a la casella objectiu) es pot considerar que aquesta és la recompensa més important i ha de tenir la mateixa importància que la resta. Per tant, un factor de descompte menor que 1 desvirtuaria el seu valor.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1FNdpDAo6Dp"
   },
   "source": [
    "Tanquem l'entorn perquè als següents apartats en crearem un de nou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4kH2b5D5o6Dq"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfRRHd3Bo6Dq"
   },
   "source": [
    "## 6. Diferència de polítiques entre SARSA i Q-Learning (1.5 punts)\n",
    "\n",
    "En aquest darrer apartat dissenyarem un entorn una mica més complicat i compararem les diferents polítiques que assoleixen els mètodes SARSA i Q-learning.\n",
    "\n",
    "Per a això es demana:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIdDvu4Eo6Dq"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 6.1</strong> (0,5 punts)\n",
    "\n",
    "Crear un entorn nou amb una graella 5x5 com la que s'observa a continuació (utilitzeu <code>\"5X5_Ex6\"</code> com a clau de l'entrada al diccionari <code>GRIDS</code>.):\n",
    "<br><br>\n",
    "<img src=\"images/Gym-Gridworld_Ex6_5x5.png\" alt=\"Mi imagen\" style=\"display: block; margin-left: auto; margin-right: auto;\">\n",
    "<br>\n",
    "Fixeu-vos que la casella inicial no es troba a dalt a l'esquerra si no a la meitat de la primera columna. Per a aconseguir això heu de crear una sub-classe de la classe <code>Gridworld</code> i afegir-la al final de l'arxiu <code>\\gym_gridworlds\\gridworld.py</code> (en el mateix arxiu teniu algun exemple).\n",
    "\n",
    "Enrecordeu-vos de registrar l'entorn a l'arxiu <code>\\gym_gridworlds\\\\\\_\\_init\\_\\_.py</code> amb els paràmetres pertinents (fixeu-vos en altres registres com es crida a una sub-classe), reiniciar el kernel del Notebook i tornar a importar els paquets.\n",
    "\n",
    "L'entorn s'ha de poder cridar amb el següent codi:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "xk7M0fuBo6Dq",
    "outputId": "bf10deea-4844-4605-b379-9156ca95aed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(25) \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Ex6-5x5-v0\", render_mode=\"human\")\n",
    "env.reset()\n",
    "env.render()\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9TNBKrI5o6Dr"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nuLNFbxo6Dr"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 6.2 - Entrenament i comparativa dels agents</strong> (1 punt)\n",
    "\n",
    "<ol>\n",
    "  <li>Entrena els 2 agents TD (SARSA i Q-learning) en el nou entorn. Ajusta els diferents paràmetres fins que els algoritmes convergeixin.</li>\n",
    "  <li>Imprimeix per pantalla la política assolida per cada agent.</li>\n",
    "  <li>Executa un episodi amb cada política i mostra els resultats (accions, recorregut i recompensa total).</li>\n",
    "  <li>Comenta els resultats. Són els resultats esperats?</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pyL5R8Reo6Dr",
    "outputId": "b535953c-d99a-4a53-ea98-d9cbba020732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space is Discrete(5) \n",
      "Observation space is Discrete(25) \n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Ex6-5x5-v0\", render_mode=None)\n",
    "\n",
    "print(\"Action space is {} \".format(env.action_space))\n",
    "print(\"Observation space is {} \".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "RSEfQOzzo6Dr",
    "outputId": "10edc0cd-4857-4118-c886-223be03c0f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30000/30000\n",
      "CPU times: total: 59 s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######################## SOLUCIÓ ###########################\n",
    "#Entrenament SARSA\n",
    "# obtain the estimated optimal policy and corresponding action-value function\n",
    "Q_sarsa, deltas = sarsa(env, num_episodes=30000, alpha=0.3, gamma= 1, epsilon=0.9, epsdecay=0.9, epsmin=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Gym-Gridworlds/Ex6-5x5-v0\", render_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DmWO1DtWo6Ds",
    "outputId": "b3fca137-30a1-4162-9aa1-4ebf94aaa988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30000/30000\n",
      "CPU times: total: 41.3 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "######################## SOLUCIÓ ###########################\n",
    "#Entrenament Q-learning\n",
    "# obtain the estimated optimal policy and corresponding action-value function\n",
    "Q_qlearning, deltas = qlearning(env, num_episodes=30000, alpha=0.3, gamma= 1, epsilon=0.75, epsdecay=1, epsmin=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "stzJkez1o6Ds",
    "outputId": "4a9df838-07a6-45f3-93aa-2fc64e950ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Right  |  Down  |\n",
      "------------------------------------------\n",
      "  Up  |  Left  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Up  |  Left  |  Stay  |  Left  |  Left  |\n",
      "------------------------------------------\n",
      "  Up  |  Down  |  Up  |  Up  |  Up  |\n",
      "------------------------------------------\n",
      "  Up  |  Right  |  Right  |  Up  |  Right  |\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "#Política SARSA\n",
    "print_policy(Q_sarsa,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Q6jJxaaco6Ds",
    "outputId": "e49cc958-4d27-4875-b74e-1c3276559175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 10 \n",
      "Action: Up -> Obs: 5 and reward: -0.1\n",
      "Action: Up -> Obs: 0 and reward: -0.1\n",
      "Action: Right -> Obs: 1 and reward: -0.1\n",
      "Action: Right -> Obs: 2 and reward: -0.1\n",
      "Action: Right -> Obs: 3 and reward: -0.1\n",
      "Action: Right -> Obs: 4 and reward: -0.1\n",
      "Action: Down -> Obs: 9 and reward: -0.1\n",
      "Action: Down -> Obs: 14 and reward: -0.1\n",
      "Action: Left -> Obs: 13 and reward: -0.1\n",
      "Action: Left -> Obs: 12 and reward: -0.1\n",
      "Action: Stay -> Obs: 12 and reward: 1.0\n",
      "Episode finished after 11 timesteps and reward was 1.1102230246251565e-16 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "#Execució episodi SARSA\n",
    "execute_episode(Q_sarsa,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sdRn3a-Lo6Dt",
    "outputId": "a9001583-a6cf-4963-d991-599296869ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Right  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Left  |  Left  |  Down  |\n",
      "------------------------------------------\n",
      "  Down  |  Left  |  Stay  |  Left  |  Left  |\n",
      "------------------------------------------\n",
      "  Down  |  Down  |  Up  |  Up  |  Left  |\n",
      "------------------------------------------\n",
      "  Right  |  Right  |  Right  |  Up  |  Left  |\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "#Política O-learning\n",
    "print_policy(Q_qlearning,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5wxk6Txko6Dt",
    "outputId": "93aaee17-a580-472b-c506-816b8e59a53c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs inicial: 10 \n",
      "Action: Down -> Obs: 15 and reward: -0.1\n",
      "Action: Down -> Obs: 20 and reward: -0.1\n",
      "Action: Right -> Obs: 21 and reward: -0.1\n",
      "Action: Right -> Obs: 22 and reward: -0.1\n",
      "Action: Right -> Obs: 23 and reward: -0.1\n",
      "Action: Up -> Obs: 18 and reward: -0.1\n",
      "Action: Up -> Obs: 13 and reward: -0.1\n",
      "Action: Left -> Obs: 12 and reward: -0.1\n",
      "Action: Stay -> Obs: 12 and reward: 1.0\n",
      "Episode finished after 9 timesteps and reward was 0.20000000000000007 \n"
     ]
    }
   ],
   "source": [
    "######################## SOLUCIÓ ###########################\n",
    "#Execució episodi Q-learning\n",
    "execute_episode(Q_qlearning,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLONPuAqo6Dt"
   },
   "source": [
    "<div style=\"background-color: #fcf2f2; border-color: #dfb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;\">\n",
    "<strong>CONCLUSIONS:</strong>\n",
    "<br>\n",
    "En base als resultats obtinguts s'observa que:  \n",
    "<ul>\n",
    "  <li>Tots 2 arriben a assolir l'objectiu.</li>\n",
    "  <li>Q-learning aprèn la política òptima. Arriba en 9 passes i obté un retorn de 0.2</li>\n",
    "  <li>SARSA aprèn una política sub-òptima més conservadora. Arriba en 11 passes i obté un retorn de 0, però evita passar a prop de les caselles amb major penalització.</li>\n",
    "</ul>\n",
    "Aquest comportament dels 2 algoritmes és l'esperat tal i com es va veure al mòdul de teoria.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
